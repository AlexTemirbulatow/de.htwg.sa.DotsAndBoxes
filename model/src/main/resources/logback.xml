<configuration>
  <appender name="ASYNC_LOGSTASH" class="ch.qos.logback.classic.AsyncAppender">
    <appender-ref ref="LOGSTASH"/>
  </appender>

  <appender name="ASYNC_KAFKA" class="ch.qos.logback.classic.AsyncAppender">
    <appender-ref ref="kafkaAppender"/>
  </appender>

  <appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
    <destination>logstash:5000</destination>
    <encoder class="net.logstash.logback.encoder.LogstashEncoder" />
  </appender>

  <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
    <encoder>
      <pattern>%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n</pattern>
    </encoder>
  </appender>

  <appender name="FILE" class="ch.qos.logback.core.FileAppender">
    <file>logging/logs/application.log</file>
    <append>true</append>
    <encoder>
      <pattern>[%-5level LOG]: [%thread] - %msg%n</pattern>
    </encoder>
  </appender>

  <appender name="kafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
    <encoder>
        <pattern>{ "level": "%-5level", "message": "%msg" }</pattern>
    </encoder>
    <topic>logs</topic>
    <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy" />
    <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />
    <appendTimestamp>true</appendTimestamp>
    <producerConfig>bootstrap.servers=localhost:9092</producerConfig>
  </appender>

  <root level="INFO">
    <appender-ref ref="STDOUT" />
    <appender-ref ref="FILE" />
    <appender-ref ref="ASYNC_LOGSTASH" />
    <appender-ref ref="ASYNC_KAFKA" />
  </root>
</configuration>
